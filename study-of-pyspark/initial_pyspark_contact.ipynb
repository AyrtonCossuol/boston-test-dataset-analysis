{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " initial_pyspark_contact.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zqvjl3C3OSh"
      },
      "source": [
        "# **Estudos Iniciais sobre PySpark**\n",
        "Notebook voltado para o aprendizado da ferramenta no ambiente Colab.\n",
        " \n",
        "Importante ressaltar as dependências utilizadas como:\n",
        "* Apache Spark 2.3.2;\n",
        "* hadoop 2.7;\n",
        "* Java 8;\n",
        "* Findspark.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF7o-1jv4q3x"
      },
      "source": [
        "## **Verificando a Versão do Java**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4Y0QUZB2ZLs",
        "outputId": "d5de6a61-44f0-4207-a7d3-6f1055e810c6"
      },
      "source": [
        "!java -version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.11\" 2021-04-20\n",
            "OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljMyN5_d5SMn"
      },
      "source": [
        "## **Configuração do Ambiente Java 8**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uSpnKoJ2oGu",
        "outputId": "00b638f6-00fb-41ee-bc19-a6dd0b9e884d"
      },
      "source": [
        "!sudo update-alternatives --config java"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There is only one alternative in link group java (providing /usr/bin/java): /usr/lib/jvm/java-11-openjdk-amd64/bin/java\n",
            "Nothing to configure.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I46AYmAA5tiN"
      },
      "source": [
        "## **Downloading Spark**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN-Ab-gj2ttd"
      },
      "source": [
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.1/spark-2.4.1-bin-hadoop2.7.tgz"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvSczX3F2-Ew",
        "outputId": "fb35e287-65cc-4cf7-f6bc-326234e151e0"
      },
      "source": [
        "!tar xf spark-2.4.1-bin-hadoop2.7.tgz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tar: spark-2.4.1-bin-hadoop2.7.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu7CDmGB3BuQ"
      },
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qCrWIHL3IGy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}